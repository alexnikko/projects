{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "SPARK_HOME = \"/usr/hdp/current/spark2-client\"\n",
    "PYSPARK_PYTHON = \"/opt/conda/envs/dsenv/bin/python\"\n",
    "os.environ[\"PYSPARK_PYTHON\"]= PYSPARK_PYTHON\n",
    "os.environ[\"SPARK_HOME\"] = SPARK_HOME\n",
    "\n",
    "PYSPARK_HOME = os.path.join(SPARK_HOME, \"python/lib\")\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"py4j-0.10.7-src.zip\"))\n",
    "sys.path.insert(0, os.path.join(PYSPARK_HOME, \"pyspark.zip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = SparkConf()\n",
    "conf.set(\"spark.ui.port\", 4123) # подставьте случайное пятизначное число\n",
    "\n",
    "spark = SparkSession.builder.config(conf=conf).appName(\"Spark ML Intro\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-10-0-1-212.us-east-2.compute.internal:4123\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2.3.1.4.0-315</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark ML Intro</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc0dda9e410>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/datasets/amazon/all_reviews_5_core_train_small.json'\n",
    "dataset = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- image: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- overall: double (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: long (nullable = true)\n",
      " |-- verified: boolean (nullable = true)\n",
      " |-- vote: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|overall|\n",
      "+-------+\n",
      "|    1.0|\n",
      "|    4.0|\n",
      "|    3.0|\n",
      "|    2.0|\n",
      "|    5.0|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.select(dataset['overall']).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dataset.select(dataset.overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|overall| count|\n",
      "+-------+------+\n",
      "|    1.0| 89431|\n",
      "|    4.0|160880|\n",
      "|    3.0| 80170|\n",
      "|    2.0| 52944|\n",
      "|    5.0|650617|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target.groupBy('overall').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1034042"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "956712"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.select('reviewerID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.select('reviewText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|          reviewText|\n",
      "+--------------------+\n",
      "|quick shipping, g...|\n",
      "|Most delicious Ever!|\n",
      "|This item was eas...|\n",
      "|good brand, good ...|\n",
      "|Piece of junk. At...|\n",
      "|I order xl. The o...|\n",
      "|The case definite...|\n",
      "|Liked most that m...|\n",
      "|goodI think it's ...|\n",
      "|I apparently don'...|\n",
      "|WARM AND COMFORTA...|\n",
      "|somehow this hat ...|\n",
      "|I was worried abo...|\n",
      "|The Best of the B...|\n",
      "|The bag is small,...|\n",
      "|This is a very br...|\n",
      "|Great shirt! Very...|\n",
      "|I'm a size 0- ord...|\n",
      "|Perfect fit. Woul...|\n",
      "|I ordered these a...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='reviewText', outputCol='reviewWords')\n",
    "\n",
    "dataset = tokenizer.transform(dataset)\n",
    "\n",
    "dataset.show(1, truncate=True, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_remover = StopWordsRemover(inputCol='reviewWords', outputCol='reviewWordsWithoutTrash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = stop_words_remover.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------\n",
      " asin                    | B00005MDZ8           \n",
      " id                      | 6500                 \n",
      " image                   | null                 \n",
      " overall                 | 5.0                  \n",
      " reviewText              | quick shipping, g... \n",
      " reviewTime              | 10 23, 2014          \n",
      " reviewerID              | AEZ4DZCUL021H        \n",
      " reviewerName            | Stephen              \n",
      " summary                 | great product        \n",
      " unixReviewTime          | 1414022400           \n",
      " verified                | true                 \n",
      " vote                    | null                 \n",
      " reviewWords             | [quick, shipping,... \n",
      " reviewWordsWithoutTrash | [quick, shipping,... \n",
      "-RECORD 1---------------------------------------\n",
      " asin                    | B000DZE0XK           \n",
      " id                      | 42580                \n",
      " image                   | null                 \n",
      " overall                 | 5.0                  \n",
      " reviewText              | Most delicious Ever! \n",
      " reviewTime              | 02 13, 2016          \n",
      " reviewerID              | A3UPMJ5WQFHGLN       \n",
      " reviewerName            | Pelipen              \n",
      " summary                 | Five Stars           \n",
      " unixReviewTime          | 1455321600           \n",
      " verified                | true                 \n",
      " vote                    | null                 \n",
      " reviewWords             | [most, delicious,... \n",
      " reviewWordsWithoutTrash | [delicious, ever!]   \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(2, truncate=True, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashing = HashingTF(numFeatures=300, binary=True, inputCol='reviewWordsWithoutTrash', outputCol=\"word_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = hashing.transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------\n",
      " asin                    | B00005MDZ8           \n",
      " id                      | 6500                 \n",
      " image                   | null                 \n",
      " overall                 | 5.0                  \n",
      " reviewText              | quick shipping, g... \n",
      " reviewTime              | 10 23, 2014          \n",
      " reviewerID              | AEZ4DZCUL021H        \n",
      " reviewerName            | Stephen              \n",
      " summary                 | great product        \n",
      " unixReviewTime          | 1414022400           \n",
      " verified                | true                 \n",
      " vote                    | null                 \n",
      " reviewWords             | [quick, shipping,... \n",
      " reviewWordsWithoutTrash | [quick, shipping,... \n",
      " word_vector             | (300,[1,55,184,26... \n",
      "-RECORD 1---------------------------------------\n",
      " asin                    | B000DZE0XK           \n",
      " id                      | 42580                \n",
      " image                   | null                 \n",
      " overall                 | 5.0                  \n",
      " reviewText              | Most delicious Ever! \n",
      " reviewTime              | 02 13, 2016          \n",
      " reviewerID              | A3UPMJ5WQFHGLN       \n",
      " reviewerName            | Pelipen              \n",
      " summary                 | Five Stars           \n",
      " unixReviewTime          | 1455321600           \n",
      " verified                | true                 \n",
      " vote                    | null                 \n",
      " reviewWords             | [most, delicious,... \n",
      " reviewWordsWithoutTrash | [delicious, ever!]   \n",
      " word_vector             | (300,[14,165],[1.... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset.show(2, truncate=True, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = dataset.select('word_vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         word_vector|\n",
      "+--------------------+\n",
      "|(300,[1,55,184,26...|\n",
      "|(300,[14,165],[1....|\n",
      "+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression, GBTRegressor\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dataset.randomSplit([0.9, 0.1], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(featuresCol='word_vector', labelCol='overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.9501105076740135 \n",
      "-RECORD 1------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 3.7980904669585294 \n",
      "-RECORD 2------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 3.6607454898977707 \n",
      "-RECORD 3------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.541608295651211  \n",
      "-RECORD 4------------------------\n",
      " overall    | 4.0                \n",
      " prediction | 4.597739674896557  \n",
      "-RECORD 5------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.466037850805992  \n",
      "-RECORD 6------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 2.3104162628407563 \n",
      "-RECORD 7------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 5.205687406845654  \n",
      "-RECORD 8------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.241129982037104  \n",
      "-RECORD 9------------------------\n",
      " overall    | 3.0                \n",
      " prediction | 3.817244714275295  \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.transform(test)\\\n",
    "    .select('overall', 'prediction')\\\n",
    "    .show(10, truncate=True, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model = GBTRegressor(featuresCol='word_vector', labelCol='overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbt_model = gbt_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.5194348302073735 \n",
      "-RECORD 1------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 3.949040996121991  \n",
      "-RECORD 2------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 3.5161389016311353 \n",
      "-RECORD 3------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.772838551671828  \n",
      "-RECORD 4------------------------\n",
      " overall    | 4.0                \n",
      " prediction | 4.130910738147576  \n",
      "-RECORD 5------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.526417922022976  \n",
      "-RECORD 6------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 2.661097654673532  \n",
      "-RECORD 7------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.580194023083057  \n",
      "-RECORD 8------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.277918902654275  \n",
      "-RECORD 9------------------------\n",
      " overall    | 3.0                \n",
      " prediction | 4.206697627049208  \n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gbt_model.transform(test)\\\n",
    "    .select('overall', 'prediction')\\\n",
    "    .show(10, truncate=True, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.191688679090648  \n",
      "-RECORD 1------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.642542898602038  \n",
      "-RECORD 2------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.373698456892848  \n",
      "-RECORD 3------------------------\n",
      " overall    | 4.0                \n",
      " prediction | 3.1519344908035647 \n",
      "-RECORD 4------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 2.9546876016495984 \n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 1.17204\n"
     ]
    }
   ],
   "source": [
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "path = '/datasets/amazon/all_reviews_5_core_train_small.json'\n",
    "data = spark.read.json(path)\n",
    "data = data.select('reviewText', 'overall')\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "train, test = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='reviewText', outputCol='reviewWords')\n",
    "stop_words_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='reviewWordsWithoutTrash')\n",
    "hashing = HashingTF(numFeatures=300, binary=True, inputCol=stop_words_remover.getOutputCol(), outputCol=\"word_vector\")\n",
    "lr = LinearRegression(featuresCol=hashing.getOutputCol(), labelCol='overall')\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stop_words_remover, hashing, lr])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select('overall', 'prediction').show(5, truncate=True, vertical=True)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.252797332720861  \n",
      "-RECORD 1------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.477268602769726  \n",
      "-RECORD 2------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 3.8387137538392184 \n",
      "-RECORD 3------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 5.270086480898681  \n",
      "-RECORD 4------------------------\n",
      " overall    | 5.0                \n",
      " prediction | 4.126752815293975  \n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 1.17276\n"
     ]
    }
   ],
   "source": [
    "path = '/datasets/amazon/all_reviews_5_core_train.json'\n",
    "data = spark.read.json(path)\n",
    "data = data.select('reviewText', 'overall')\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "train, test = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='reviewText', outputCol='reviewWords')\n",
    "stop_words_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='reviewWordsWithoutTrash')\n",
    "hashing = HashingTF(numFeatures=300, binary=True, inputCol=stop_words_remover.getOutputCol(), outputCol=\"word_vector\")\n",
    "lr = LinearRegression(featuresCol=hashing.getOutputCol(), labelCol='overall')\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stop_words_remover, hashing, lr])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select('overall', 'prediction').show(5, truncate=True, vertical=True)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-----------------------\n",
      " overall    | 5.0               \n",
      " prediction | 4.052440714707367 \n",
      "-RECORD 1-----------------------\n",
      " overall    | 5.0               \n",
      " prediction | 4.077742239037248 \n",
      "-RECORD 2-----------------------\n",
      " overall    | 4.0               \n",
      " prediction | 4.805718073446657 \n",
      "-RECORD 3-----------------------\n",
      " overall    | 5.0               \n",
      " prediction | 4.69261489758261  \n",
      "-RECORD 4-----------------------\n",
      " overall    | 5.0               \n",
      " prediction | 4.28826739601142  \n",
      "only showing top 5 rows\n",
      "\n",
      "Root Mean Squared Error (RMSE) on test data = 1.00306\n"
     ]
    }
   ],
   "source": [
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "path = '/datasets/amazon/all_reviews_5_core_train_small.json'\n",
    "data = spark.read.json(path)\n",
    "data = data.select('reviewText', 'overall')\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "train, test = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "tokenizer = Tokenizer(inputCol='reviewText', outputCol='reviewWords')\n",
    "stop_words_remover = StopWordsRemover(inputCol=tokenizer.getOutputCol(), outputCol='reviewWordsWithoutTrash')\n",
    "vectorizer = CountVectorizer(inputCol=stop_words_remover.getOutputCol(), outputCol=\"word_vector\", minDF=150)\n",
    "lr = LinearRegression(featuresCol=hashing.getOutputCol(), labelCol='overall')\n",
    "\n",
    "\n",
    "pipeline = Pipeline(stages=[tokenizer, stop_words_remover, vectorizer, lr])\n",
    "\n",
    "# Train model.  This also runs the indexer.\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select('overall', 'prediction').show(5, truncate=True, vertical=True)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"overall\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/datasets/amazon/all_reviews_5_core_train.json'\n",
    "data = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------------------------\n",
      " asin           | 0783225911           \n",
      " id             | 234                  \n",
      " image          | null                 \n",
      " overall        | 5.0                  \n",
      " reviewText     | great                \n",
      " reviewTime     | 03 4, 2017           \n",
      " reviewerID     | A2U0QAHUCW6ZGZ       \n",
      " reviewerName   | Debop                \n",
      " summary        | Five Stars           \n",
      " unixReviewTime | 1488585600           \n",
      " verified       | true                 \n",
      " vote           | null                 \n",
      "-RECORD 1------------------------------\n",
      " asin           | 630580785X           \n",
      " id             | 4637                 \n",
      " image          | null                 \n",
      " overall        | 3.0                  \n",
      " reviewText     | Another one banne... \n",
      " reviewTime     | 09 16, 2001          \n",
      " reviewerID     | A1KLJA9E10SAGP       \n",
      " reviewerName   | Dave B               \n",
      " summary        | Now this is shock... \n",
      " unixReviewTime | 1000598400           \n",
      " verified       | false                \n",
      " vote           | 5                    \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(2, truncate=True, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1], [2]])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = a\n",
    "for i in range(5000-1):\n",
    "    res = np.hstack((res, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 5000)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 1, 1, 1],\n",
       "       [2, 2, 2, ..., 2, 2, 2]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(a, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((a, a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
